{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整体架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分为召回和排序两个阶段，其中召回阶段进行比较粗糙的筛选，即使用较少的特征来过滤掉较多的物品得到候选集，比如从百万商品中选出几百个商品；排序阶段使用更加细致的特征来对候选集（几百）进行排序，最终选择很少一部分数据来做呈现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 召回阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 召回阶段使用深度模型主要的好处有：1.end-to-end，不用太多的人工干预，自动进行训练和学习，特征提取比较方便；2.发掘非线性的特征，而这些规律是人工不容易发掘的。\n",
    "### 召回阶段可以理解为一个超大规模的多分类问题。即在某一时刻为用户在视频库中精确的预测处视频的类别，由于每个视频就是一个分类，所以预测的就是某个视频。而DNN的任务就是将用户以及上下文的信息作为输入，学习用户的embedding向量u,通过一个softmax分类器，u能够有效的从视频库中识别视频类别。\n",
    "### 输入层可以是用户浏览历史，搜索历史，人口统计学信息和其余的上下文信息；\n",
    "### 中间是三个隐层的DNN结构\n",
    "### 离线训练阶段输出层为softmax层，进行反向传播；服务阶段直接用user embedding和item embedding计算dot-product表示分数，去top-n为候选结果，性能问题通过LSH来解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 排序阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序阶段更精确的预估用户的喜好，使用了更多的特征。\n",
    "### 输入层采用embedding的方式映射稀疏离散特征为密集向量，为每一个类别特征维度生成一个独立的embedding空间,对于相同域的特征可以共享embedding,好处在于加速迭代，降低内存开销。实数的特征可以进行特征构造，进行非线性的构造。\n",
    "### 中间是三个隐层的DNN结构\n",
    "### 训练阶段为逻辑回归，服务阶段使用sigmoid函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
